# Model Router f√ºr VSCode/Cursor mit Guido Voice Control üé§

> Sprache / Language: **Deutsch** | [English](./README.en.md)

<!-- TOC START -->
<!-- TOC END -->

Eine intelligente VSCode-Extension, die **automatisch das optimale KI-Modell** f√ºr jede Aufgabe ausw√§hlt. Mit **vollst√§ndiger Sprachsteuerung "Guido"**, Unterst√ºtzung f√ºr OpenAI, DeepSeek, Grok, Phi, Ollama und anderen Providern.

## üéØ Features

### ‚ö° Intelligentes Routing
- **Automatische Modellauswahl** basierend auf Prompt-Inhalt, Dateityp und Kontext
- **Regelbasiertes System** mit anpassbaren Routing-Regeln
- **Optionaler LLM-Classifier** f√ºr erweiterte Prompt-Analyse
- **Fallback-Mechanismen** bei Ausf√§llen oder Rate Limits

### üåê Multi-Provider-Unterst√ºtzung
- **OpenAI** (GPT-4o, GPT-4o-mini, GPT-4.1)
- **DeepSeek** (v3, r1 Reasoning)
- **Grok** (xAI)
- **Microsoft Phi** (4, 4-mini)
- **Ollama** (lokale Modelle: Llama, Qwen, CodeLlama)
- **Beliebige OpenAI-kompatible APIs**

### üí∞ Kostenbewusstsein
- **Live-Kostensch√§tzung** vor Ausf√ºhrung
- **Budget-Management** mit Tages- und Monatslimits
- **Ausgaben-Tracking** und Statistiken
- **Preisvergleich** zwischen Modellen

### üîí Sicherheit & Datenschutz
- **Sichere API-Key-Speicherung** √ºber VSCode SecretStorage
- **Privacy-Modi**: `privacy-strict`, `local-only`, `offline`
- **Datenschutz-Filter** f√ºr sensible Dateipfade
- **Keine Klartext-Speicherung** von Geheimnissen

### üé® Benutzerfreundlichkeit & UI

- **Webview Chat Panel** (floating) & **andockbare Chat-View** im Explorer
- **Model Override Dropdown** direkt im Chat
- **Anh√§nge-Zusammenfassung** (Snippet, Secret-Redaktion konfigurierbar)
- **Kosten-Footer** mit tats√§chlichen Tokenwerten
- **Tools-Men√º** (Routing-Simulation, Budget, Resend, Clear)
- **Plan / Agent**: Schrittplan generieren (Ausbau geplant: Ausf√ºhrung)
- **Voice-State Indikator** (idle / listening / recording / processing)
- **Statusbar-Integration** (Modus + optional Budget)
- **QuickPrompt-Kompaktmodus** f√ºr schnelle Prompts ohne Panel
- **Command Palette** Integration kompletter Funktionen

## üöÄ Installation

### 1. Voraussetzungen

- VSCode 1.90.0 oder neuer
- Node.js 20+ (f√ºr Entwicklung)
- Optional: Ollama f√ºr lokale Modelle

### 2. Extension installieren

#### Entwicklungsversion (empfohlen)

```bash
# Repository klonen
git clone <repository-url>
cd model-router

# Dependencies installieren
npm install

# TypeScript kompilieren
npm run compile

# Extension in VSCode laden
# F5 dr√ºcken oder "Run Extension" in der Debug-Ansicht
```

#### Aus Package installieren

```bash
# Extension packen
npm run package

# In VSCode installieren: Ctrl+Shift+P -> "Extensions: Install from VSIX"
```

### 3. Konfiguration einrichten

Die Extension erstellt automatisch eine Standard-Konfiguration:
```
workspace/
‚îú‚îÄ‚îÄ router.config.yaml    # Haupt-Konfiguration
‚îî‚îÄ‚îÄ .vscode/
    ‚îî‚îÄ‚îÄ settings.json     # VSCode-Einstellungen
```

## ‚öôÔ∏è Konfiguration

### Basis-Konfiguration (router.config.yaml)

```yaml
version: 1
activeProfile: default

profiles:
  default:
    mode: auto  # auto|speed|quality|cheap|local-only|privacy-strict
    
    budget:
      dailyUSD: 2.50
      hardStop: true
      warningThreshold: 80
    
    privacy:
      redactPaths: ["**/secrets/**", "**/.env*"]
      stripFileContentOverKB: 256
      allowExternal: true
    
    providers:
      # OpenAI
      - id: openai
        kind: openai-compat
        baseUrl: https://api.openai.com/v1
        apiKeyRef: OPENAI_API_KEY
        models:
          - name: gpt-4o-mini
            context: 128000
            caps: ["cheap","tools","json"]
            price:
              inputPerMTok: 0.15
              outputPerMTok: 0.60
      
      # Lokale Modelle via Ollama
      - id: ollama
        kind: ollama
        baseUrl: http://127.0.0.1:11434
        models:
          - name: llama3.3:70b-instruct
            context: 32768
            caps: ["local","long","tools"]
    
    routing:
      rules:
        # Tests ‚Üí g√ºnstige Modelle
        - id: cheap-tests
          if:
            anyKeyword: ["test", "unit test", "boilerplate"]
            fileLangIn: ["ts","js","py"]
          then:
            prefer: ["openai:gpt-4o-mini"]
            target: chat
        
        # Privacy ‚Üí lokal erzwingen
        - id: privacy
          if:
            privacyStrict: true
          then:
            prefer: ["ollama:llama3.3:70b-instruct"]
            target: chat
      
      default:
        prefer: ["openai:gpt-4o-mini", "ollama:llama3.3:70b-instruct"]
        target: chat
```

### VSCode-Einstellungen

```json
{
  "modelRouter.configPath": "${workspaceFolder}/router.config.yaml",
  "modelRouter.mode": "auto",
  "modelRouter.enablePromptClassifier": false
}
```

## üîë API-Keys einrichten

### Methode 1: Command Palette

1. `Ctrl+Shift+P` ‚Üí "Model Router: Set API Key"
2. Provider-ID eingeben (z.B. `openai`)
3. API-Key eingeben

### Methode 2: Umgebungsvariablen

```bash
# .env oder System-Umgebung
export OPENAI_API_KEY="sk-..."
export DEEPSEEK_API_KEY="sk-..."
export GROK_API_KEY="..."
```

Dann: `Ctrl+Shift+P` ‚Üí "Model Router: Import API Keys"

### Unterst√ºtzte Provider

| Provider | API-Key Format | Basis-URL |
|----------|----------------|-----------|
| OpenAI | `sk-...` | `https://api.openai.com/v1` |
| DeepSeek | `sk-...` | `https://api.deepseek.com/v1` |
| Grok (xAI) | varies | `https://api.x.ai/v1` |
| Phi | varies | provider-specific |
| Ollama | none | `http://127.0.0.1:11434` |

## üéÆ Nutzung

### Chat-Interface Varianten

1. Panel (floating):

```text
Ctrl+Shift+P ‚Üí "Model Router: Open Chat UI"
```

1. Docked View (Explorer): automatisch sichtbar falls Einstellung aktiv (`modelRouter.chat.showDockView`).

Funktionen im Chat:

- Eingabefeld mit Shift+Enter = Zeilenumbruch, Enter = Senden
- Toolbar Buttons: Tools, Mikrofon (Voice starten), Speaker (Placeholder), Attach (Dateien ausw√§hlen), Plan, Settings
- Modell-Auswahl (Override) oben links (`auto` = Router entscheidet)
- Anh√§nge werden vor Versand auf max. Anzahl/Gr√∂√üe gek√ºrzt und Geheimnisse (Regex) geschw√§rzt
- Streaming der Antwort in Nachricht, Abschluss zeigt Token & Kosten
- Info-Messages (Simulation, Plan, Budget) erscheinen kursiv

QuickPrompt (Kompaktmodus):

```text
Einstellung: "modelRouter.chat.compactMode": true
Command: "Model Router: Quick Prompt (Kompaktmodus)"
```
Sendet Prompt ohne zuerst Panel zu √∂ffnen. Falls Chat offen ist, wird dort gestreamt, sonst Output-Channel.
### Docked Chat View

Die andockbare Ansicht (`üí¨ Model Router Chat (Dock)`) zeigt denselben Verlauf wie das Panel. Beide Oberfl√§chen sind synchron (Modelle, History, Streaming). Zum Ausblenden: Rechtsklick auf Titel ‚Üí Hide oder Einstellung `modelRouter.chat.showDockView` deaktivieren.

### Tools-Men√º

Command oder Toolbar ‚Üí Optionen:

- Routing-Simulation (zeigt ausgew√§hltes Modell + Alternativen)
- Kosten / Budget √úbersicht (heute / Monat / total)
- Letzte Antwort erneut senden
- Verlauf l√∂schen (auch Persistenz zur√ºckgesetzt)

### Plan / Agent

Erzeugt einen nummerierten Plan (max 7 Schritte). Aktuell nur Planung; zuk√ºnftige Version f√ºhrt Schritte sequenziell aus mit Zwischen-Feedback.

### Anh√§nge & Redaktion

Konfigurierbar √ºber Einstellungen:

```json
{
  "modelRouter.chat.attachment.maxFiles": 5,
  "modelRouter.chat.attachment.maxSnippetBytes": 8192,
  "modelRouter.chat.attachment.redactSecrets": true,
  "modelRouter.chat.attachment.additionalRedactPatterns": [
    "(?i)password\\s*[:=]\\s*['\"]?[A-Za-z0-9!@#$%^&*_-]{6,}"
  ]
}
```
Zu gro√üe Dateien (>512KB) werden √ºbersprungen. Nur die ersten N Bytes (Snippet) werden angezeigt. Geheimnisse durch Regex ‚Üí `[REDACTED]`.

### Persistenter Verlauf

`modelRouter.chat.persistHistory`: speichert die letzten 1000 Nachrichten (user/assistant) in globalState. Abschaltbar f√ºr Privacy.

### Voice-State Integration

Wenn Voice aktiviert ist (Konfig), wird der Zustand live im Chat angezeigt (idle/listening/recording/processing). Wechsel per Voice Commands / Toolbar.

### Neue Commands (Zusatz)

| Command | Zweck |
|---------|-------|
| Model Router: Open Chat UI | Panel √∂ffnen |
| Model Router: Quick Prompt (Kompaktmodus) | Schneller Prompt ohne Panel |
| Model Router: Chat Tools | Tools-Men√º |
| Model Router: Plan / Agent aus letztem Prompt | Plan generieren |
| Model Router: Ausgef√ºhrten Plan starten | (Platzhalter zuk√ºnftige Ausf√ºhrung) |
| Model Router: Plan-Ausf√ºhrung abbrechen | Stoppt geplante Ausf√ºhrung (geplant) |

### Relevante Einstellungen (Erweiterung)

| Einstellung | Beschreibung |
|------------|--------------|
| modelRouter.chat.compactMode | QuickPrompt statt Panel-Fluss |
| modelRouter.chat.persistHistory | Verlauf zwischen Sessions speichern |
| modelRouter.chat.showDockView | Docked Chat im Explorer |
| modelRouter.chat.attachment.maxFiles | Max. Anzahl Anh√§nge |
| modelRouter.chat.attachment.maxSnippetBytes | Snippet-Limit pro Datei |
| modelRouter.chat.attachment.redactSecrets | Aktiviert automatische Geheimnis-Redaktion |
| modelRouter.chat.attachment.additionalRedactPatterns | Zus√§tzliche Regexe |

### Einmaliges Routing

```text
Ctrl+Shift+P ‚Üí "Model Router: Route Prompt Once"
```

- Text im Editor ausw√§hlen
- Modellvorschlag ohne Ausf√ºhrung
- Zeigt Score und Begr√ºndung

### Modi wechseln

Klick auf Statusbar oder:

```text
Ctrl+Shift+P ‚Üí "Model Router: Switch Mode"
```

**Verf√ºgbare Modi:**

- `auto` ‚Äì Intelligente Auswahl basierend auf Kontext
- `speed` ‚Äì Schnellste verf√ºgbare Modelle
- `quality` ‚Äì Hochwertigste Modelle (teurer)
- `cheap` ‚Äì G√ºnstigste Modelle
- `local-only` ‚Äì Nur lokale Modelle (Ollama)
- `privacy-strict` ‚Äì Strenger Datenschutz, keine externen APIs

### Weitere Commands

| Command | Beschreibung |
|---------|--------------|
| `Model Router: Open Config` | Konfigurationsdatei √∂ffnen |
| `Model Router: Show Costs` | Ausgaben-√úbersicht |
| `Model Router: Test Connection` | Provider-Verbindungen testen |
| `Model Router: Classify Prompt` | Prompt-Klassifikation anzeigen |
| `Model Router: Simulate Routing` | Routing simulieren |

## üìä Routing-Regeln

### Regel-Struktur

```yaml
- id: regel-name
  if:
    anyKeyword: ["test", "debug"]      # Enth√§lt eines dieser W√∂rter
    allKeywords: ["fix", "bug"]        # Enth√§lt alle diese W√∂rter  
    fileLangIn: ["ts", "js", "py"]     # Dateityp
    filePathMatches: ["**/test/**"]    # Pfad-Pattern
    minContextKB: 128                  # Mindest-Dateigr√∂√üe
    maxContextKB: 512                  # Maximal-Dateigr√∂√üe
    privacyStrict: true                # Privacy-Modus
    mode: ["quality", "speed"]         # Aktiver Modus
  then:
    prefer: ["provider:model", "..."]  # Bevorzugte Modelle
    target: chat                       # Ziel-Art
    priority: 10                       # Zus√§tzliche Priorit√§t
```

### Beispiel-Regeln

```yaml
# Unit Tests ‚Üí g√ºnstige Modelle
- id: unit-tests
  if:
    anyKeyword: ["test", "spec", "jest", "pytest"]
    fileLangIn: ["ts", "js", "py"]
  then:
    prefer: ["openai:gpt-4o-mini", "phi:phi-4-mini"]
    target: chat

# Komplexe Algorithmen ‚Üí Reasoning-Modelle  
- id: complex-algorithms
  if:
    anyKeyword: ["algorithm", "complexity", "optimize", "prove"]
  then:
    prefer: ["deepseek:deepseek-r1", "openai:gpt-4.1"]
    target: chat

# Gro√üe Refactorings ‚Üí Long-Context
- id: large-refactor
  if:
    minContextKB: 200
    anyKeyword: ["refactor", "restructure"]
  then:
    prefer: ["openai:gpt-4.1", "phi:phi-4"]
    target: chat

# Privacy-Mode ‚Üí nur lokal
- id: privacy-only
  if:
    privacyStrict: true
  then:
    prefer: ["ollama:llama3.3:70b-instruct"]
    target: chat
```

## üí∞ Budget-Management

### Konfiguration

```yaml
budget:
  dailyUSD: 5.0        # Tagesdeckel
  monthlyUSD: 100.0    # Monatsdeckel  
  hardStop: true       # Bei √úberschreitung stoppen
  warningThreshold: 80 # Warnung bei 80% Verbrauch
```

### Kosten-Tracking

- Automatische Kostenerfassung nach jeder API-Anfrage
- Aufschl√ºsselung nach Provider und Modell
- Export f√ºr externe Analyse
- Budget-Warnungen und Hard-Stops

### Commands

```text
Model Router: Show Costs     # Ausgaben-√úbersicht
```

### Statusbar-Anzeige (Budget)

Die Statusleiste zeigt ‚Äì sofern aktiviert ‚Äì den aktuellen Modus und optional den Budgetverbrauch an.

Einstellungen (`settings.json`):
```json
{
  "modelRouter.showBudgetInStatusBar": true,
  "modelRouter.budgetDisplayMode": "compact" // oder "detailed"
}
```

Modi:
- `compact`: `Router: auto (2) | $0.12/2.50`
- `detailed`: `Router: auto (2) | d:0.12/2.50 (5%) m:2.30/100 (2%)`

Legende:
- `d:` Tagesverbrauch / Tageslimit (+ Prozent)
- `m:` Monatsverbrauch / Monatslimit (+ Prozent)
- Fehlt ein Monatsbudget, wird nur der Tageswert angezeigt.

Farbanpassung erfolgt aktuell nicht dynamisch; Warnungen (z.B. 80% erreicht) erscheinen als VSCode-Notification und im Output-Channel. Hard-Stops verhindern weitere Aufrufe √ºber dem Limit, sofern `hardStop: true` gesetzt ist.

Zeigt:
- Tagesausgaben vs. Budget
- Monatsausgaben vs. Budget  
- Transaktionsanzahl
- Top-Provider und -Modelle
- Ausgaben-Trend

## üîí Datenschutz & Sicherheit

### API-Key-Sicherheit
- **VSCode SecretStorage**: Nutzt System-Keychain (Windows Credential Manager, macOS Keychain, Linux Secret Service)
- **Keine Klartext-Speicherung**: Keys werden nie in Konfigurationsdateien gespeichert
- **Umgebungsvariablen-Fallback**: Sichere Alternative f√ºr Team-Setups

### Privacy-Modi

**`privacy-strict` Modus:**
- Erzwingt lokale Modelle (Ollama)
- Blockiert alle externen API-Calls
- Redaktiert sensible Dateipfade
- Strippt gro√üe Dateien automatisch

**Datenschutz-Filter:**
```yaml
privacy:
  redactPaths: 
    - "**/secrets/**"
    - "**/.env*" 
    - "**/credentials/**"
  stripFileContentOverKB: 256
  allowExternal: false  # Bei privacy-strict
```

### Offline-Betrieb
```yaml
mode: offline  # oder local-only
```
- Nur Ollama-Provider aktiv
- Keine Internetverbindung erforderlich
- Vollst√§ndig lokale Verarbeitung

## üõ†Ô∏è Entwicklung

### Setup
```bash
git clone <repo>
cd model-router
npm install
npm run compile
```

### Struktur
```
src/
‚îú‚îÄ‚îÄ extension.ts           # VSCode Extension Entry Point
‚îú‚îÄ‚îÄ config.ts             # YAML-Konfiguration  
‚îú‚îÄ‚îÄ router.ts             # Routing-Engine
‚îú‚îÄ‚îÄ secret.ts             # API-Key-Management
‚îú‚îÄ‚îÄ price.ts              # Kostenberechnung
‚îú‚îÄ‚îÄ promptClassifier.ts   # KI-Klassifikation
‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îú‚îÄ‚îÄ base.ts          # Provider-Interface
‚îÇ   ‚îú‚îÄ‚îÄ openaiCompat.ts  # OpenAI-kompatibel
‚îÇ   ‚îî‚îÄ‚îÄ ollama.ts        # Lokale Modelle
‚îî‚îÄ‚îÄ mcp/
    ‚îî‚îÄ‚îÄ server.ts        # MCP-Integration
```

### Testing
```bash
# Extension in Development Host starten
npm run watch    # Auto-compile
F5              # Launch Extension Development Host

# Provider-Verbindungen testen
Ctrl+Shift+P ‚Üí "Model Router: Test Connection"

# Routing-Simulation
Ctrl+Shift+P ‚Üí "Model Router: Simulate Routing"
```

### Neue Provider hinzuf√ºgen
1. Provider-Klasse in `src/providers/` erstellen
2. `BaseProvider` erweitern
3. In `extension.ts` registrieren
4. Konfiguration in `router.config.yaml` erg√§nzen

## üîß Problembehandlung

### H√§ufige Probleme

**"Router nicht initialisiert"**
- Konfigurationsdatei pr√ºfen: `Model Router: Open Config`
- API-Keys setzen: `Model Router: Set API Key`
- Extension neu laden: `Developer: Reload Window`

**"Provider nicht verf√ºgbar"**
- Verbindung testen: `Model Router: Test Connection`
- API-Key pr√ºfen
- Firewall/Proxy-Einstellungen √ºberpr√ºfen

**"Kein passendes Modell gefunden"**
- Routing-Regeln in Konfiguration pr√ºfen
- Fallback-Modelle definieren
- Provider-Verf√ºgbarkeit testen

**Ollama-Probleme**
```bash
# Ollama installieren
curl -fsSL https://ollama.ai/install.sh | sh

# Modell laden
ollama pull llama3.3:70b-instruct
ollama pull qwen2.5-coder:32b-instruct

# Server starten
ollama serve
```

### Logs aktivieren
Output-Channel √∂ffnen: "View" ‚Üí "Output" ‚Üí "Model Router"

### Debug-Mode
```json
{
  "modelRouter.debug": true
}
```

## ü§ù Beitragen

### Issues
- Bug-Reports mit reproduzierbaren Schritten
- Feature-Requests mit Use-Cases
- Provider-spezifische Probleme mit Logs

### Pull Requests
1. Fork erstellen
2. Feature-Branch: `git checkout -b feature/neue-funktion`
3. Tests hinzuf√ºgen
4. PR erstellen mit Beschreibung

### Provider-Requests
Neue Provider k√∂nnen angefragt werden. Ben√∂tigt:
- API-Dokumentation
- Preismodell
- Beispiel-API-Keys (f√ºr Tests)

## üìã Roadmap

### v0.2.0
- [ ] Webview-Chat-Interface
- [ ] Tool-Calling-Unterst√ºtzung
- [ ] Vollst√§ndige MCP-Integration
- [ ] Team-Konfigurationen

### v0.3.0
- [ ] Anthropic Claude Support
- [ ] Azure OpenAI Integration
- [ ] Performance-Benchmarking
- [ ] A/B-Testing f√ºr Modelle

### v0.4.0
- [ ] Workflow-Automatisierung
- [ ] GitHub Copilot Integration
- [ ] Enterprise-Features
- [ ] Telemetrie-Dashboard

## üìÑ Lizenz

MIT License - siehe [LICENSE](LICENSE) f√ºr Details.

## üôè Danksagungen

- VSCode Team f√ºr die Extension API
- OpenAI, DeepSeek, xAI f√ºr die APIs
- Ollama Community f√ºr lokale Modelle
- MCP-Protokoll Contributors

---

**Weitere Fragen?** √ñffne ein [Issue](../../issues) oder schaue in die [Diskussionen](../../discussions).
