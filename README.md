# Model Router f√ºr VSCode/Cursor mit Guido Voice Control üé§

> Sprache / Language: **Deutsch** | [English](./README.en.md)

<!-- TOC START -->
<!-- TOC END -->

Eine intelligente VSCode-Extension, die **automatisch das optimale KI-Modell** f√ºr jede Aufgabe ausw√§hlt. Mit **vollst√§ndiger Sprachsteuerung "Guido"**, Unterst√ºtzung f√ºr OpenAI, DeepSeek, Grok, Phi, Ollama und anderen Providern.

## üéØ Features

### ‚ö° Intelligentes Routing

- Automatische Modellauswahl (Prompt-Inhalt, Dateityp, Kontext)
- Regelbasiertes System + optionaler LLM-Classifier
- Fallback-Mechanismen (Ausf√§lle, Rate Limits)

### üåê Multi-Provider-Unterst√ºtzung

- OpenAI (GPT‚Äë4o, GPT‚Äë4o-mini, GPT‚Äë4.1)
- DeepSeek (v3, r1 Reasoning)
- Grok (xAI)
- Microsoft Phi (4, 4-mini)
- Ollama (lokal: Llama, Qwen, CodeLlama)
- Beliebige OpenAI-kompatible APIs

### üí∞ Kostenbewusstsein

- Live-Kostensch√§tzung vor Ausf√ºhrung
- Budget (Tag/Monat) + Hard-Stop + Warnschwelle
- Ausgaben-Tracking & Statistiken
- Preisvergleich je Modell

### üîí Sicherheit & Datenschutz

- Sichere SecretStorage API-Key Ablage
- Privacy-Modi: `privacy-strict`, `local-only`, `offline`
- Redaktions-Filter & Pfad-Regeln
- Keine Klartext-Speicherung sensibler Werte

### üé® UI & Bedienung

- Floating Chat Panel & Dock-View (synchron)
- Model Override Dropdown
- Anh√§nge-Zusammenfassung + Secret-Redaktion
- Kosten-Footer (tats√§chliche Usage)
- Tools-Men√º (Simulation, Budget, Resend, Clear)
- Plan / Agent: Plan erzeugen & Schritte sequenziell ausf√ºhren (Streaming & Abbruch)
- Statusbar: Modus, Budget, Plan-Fortschritt `$(sync~spin) Plan 2/5`
- Voice-State Indikator (idle/listening/recording/processing)
- QuickPrompt Kompaktmodus
- Vollst√§ndige Command-Palette Integration

## üöÄ Installation

### 1. Voraussetzungen

- VSCode 1.90.0+
- Node.js 20+
- Optional: Ollama f√ºr lokale Modelle

### 2. Entwicklungsversion

```bash
git clone <repository-url>
cd model-router
npm install
npm run compile
# F5 in VSCode (Run Extension)
```

### 3. Aus VSIX

```bash
npm run package
# VSCode: Extensions: Install from VSIX
```

### 4. Struktur

```text
workspace/
‚îú‚îÄ‚îÄ router.config.yaml
‚îî‚îÄ‚îÄ .vscode/settings.json
```

## ‚öôÔ∏è Konfiguration

### Beispiel `router.config.yaml`

```yaml
version: 1
activeProfile: default

profiles:
  default:
    mode: auto
    budget:
      dailyUSD: 2.50
      monthlyUSD: 50
      hardStop: true
      warningThreshold: 80
    privacy:
      redactPaths: ["**/secrets/**", "**/.env*"]
      stripFileContentOverKB: 256
      allowExternal: true
    providers:
      - id: openai
        kind: openai-compat
        baseUrl: https://api.openai.com/v1
        apiKeyRef: OPENAI_API_KEY
        models:
          - name: gpt-4o-mini
            context: 128000
            caps: ["cheap","tools","json"]
            price:
              inputPerMTok: 0.15
              outputPerMTok: 0.60
      - id: ollama
        kind: ollama
        baseUrl: http://127.0.0.1:11434
        models:
          - name: llama3.3:70b-instruct
            context: 32768
            caps: ["local","long","tools"]
    routing:
      rules:
        - id: cheap-tests
          if:
            anyKeyword: ["test","unit test","boilerplate"]
            fileLangIn: ["ts","js","py"]
          then:
            prefer: ["openai:gpt-4o-mini"]
            target: chat
        - id: privacy
          if:
            privacyStrict: true
          then:
            prefer: ["ollama:llama3.3:70b-instruct"]
            target: chat
      default:
        prefer: ["openai:gpt-4o-mini","ollama:llama3.3:70b-instruct"]
        target: chat
```

### VSCode Settings (`settings.json`)

```json
{
  "modelRouter.configPath": "${workspaceFolder}/router.config.yaml",
  "modelRouter.mode": "auto",
  "modelRouter.enablePromptClassifier": false
}
```

## üîë API-Keys

### Methode 1 (Command Palette)
1. Ctrl+Shift+P ‚Üí "Model Router: Set API Key"
2. Provider-ID (z.B. `openai`)
3. Key eingeben

### Methode 2 (Environment)

```bash
export OPENAI_API_KEY="sk-..."
export DEEPSEEK_API_KEY="sk-..."
```

Dann: Ctrl+Shift+P ‚Üí "Model Router: Import API Keys"

## üéÆ Nutzung

### Chat Varianten

Floating Panel: Command "Model Router: Open Chat UI"

Docked View: aktiv bei Setting `modelRouter.chat.showDockView`.

**Funktionen:** Streaming, Modell-Override, Anh√§nge (Snippet + Redaction), Kosten-Footer, Tools, Plan, Voice-State.

### QuickPrompt

```text
Setting "modelRouter.chat.compactMode": true
Command "Model Router: Quick Prompt (Kompaktmodus)"
```

### Plan / Agent

1. "Plan / Agent aus letztem Prompt" ‚Üí nummerierter Plan (‚â§7)
2. "Ausgef√ºhrten Plan starten" ‚Üí sequentielle Ausf√ºhrung
3. "Plan-Ausf√ºhrung abbrechen" ‚Üí Abort aktueller Schritt

W√§hrenddessen:
- Jeder Schritt eigenes Routing & Streaming
- Kosten pro Schritt erfasst (Budget aktiv)
- Verlaufseintr√§ge: `[Plan Schritt X]` + Antwort
- Statusbar: `$(sync~spin) Plan X/N`

Nach Abschluss / Abbruch verschwindet der Indikator.

### Anh√§nge Einstellungen

```json
{
  "modelRouter.chat.attachment.maxFiles": 5,
  "modelRouter.chat.attachment.maxSnippetBytes": 8192,
  "modelRouter.chat.attachment.redactSecrets": true,
  "modelRouter.chat.attachment.additionalRedactPatterns": [
    "(?i)password\\s*[:=]\\s*['\"]?[A-Za-z0-9!@#$%^&*_-]{6,}"
  ]
}
```

### Persistenter Verlauf
`modelRouter.chat.persistHistory` speichert letzte 1000 Nachrichten (abschaltbar).

### Relevante Commands

| Command | Zweck |
|---------|-------|
| Open Chat UI | Chat Panel √∂ffnen |
| Quick Prompt (Kompaktmodus) | Schneller Prompt ohne Panel |
| Chat Tools | Tools-Men√º |
| Plan / Agent aus letztem Prompt | Plan generieren |
| Ausgef√ºhrten Plan starten | Plan ausf√ºhren |
| Plan-Ausf√ºhrung abbrechen | Laufende Ausf√ºhrung abbrechen |
| Show Costs | Kosten√ºbersicht |
| Switch Mode | Modus wechseln |

## üìä Routing-Regeln

Beispiel siehe oben (Konfiguration). Bedingungen: `anyKeyword`, `fileLangIn`, `privacyStrict`, Gr√∂√üenbeschr√§nkungen etc.

## üí∞ Budget & Statusbar

Statusbar zeigt Modus + optional Budget + Plan-Fortschritt.

Settings:
```json
{
  "modelRouter.showBudgetInStatusBar": true,
  "modelRouter.budgetDisplayMode": "compact"
}
```

Plan-Beispiel:
```text
$(rocket) Router: auto (2) | $0.12/2.50 | $(sync~spin) Plan 2/5
```

## üîí Datenschutz

`privacy-strict` erzwingt lokale Modelle, blockt externe Calls, redaktiert Pfade.

```yaml
privacy:
  redactPaths:
    - "**/secrets/**"
    - "**/.env*"
  stripFileContentOverKB: 256
  allowExternal: false
```

## üõ† Entwicklung

```bash
npm install
npm run watch
# F5 Development Host
```

Struktur:
```text
src/
‚îú‚îÄ‚îÄ extension.ts
‚îú‚îÄ‚îÄ config.ts
‚îú‚îÄ‚îÄ router.ts
‚îú‚îÄ‚îÄ secret.ts
‚îú‚îÄ‚îÄ price.ts
‚îú‚îÄ‚îÄ promptClassifier.ts
‚îú‚îÄ‚îÄ providers/
‚îî‚îÄ‚îÄ mcp/server.ts
```

## üîß Problembehandlung

**Router nicht initialisiert**: Config pr√ºfen, API-Key setzen, Fenster reload.

**Provider nicht verf√ºgbar**: Verbindung testen, Key pr√ºfen, Proxy/Firewall.

**Kein Modell gefunden**: Routing-Regeln / Fallbacks anpassen.

**Ollama**:
```bash
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull llama3.3:70b-instruct
ollama serve
```

## üìã Roadmap

### v0.2.0
- Tool-Calling
- MCP-Vertiefung
- Team-Konfigurationen

### v0.3.0
- Anthropic Claude
- Azure OpenAI
- Benchmarks / A-B Tests

### v0.4.0
- Workflow-Automatisierung
- Enterprise / Telemetrie Dashboard

## üìÑ Lizenz

MIT ‚Äì siehe [LICENSE](LICENSE).

## üôè Danksagungen

VSCode Team ¬∑ OpenAI ¬∑ DeepSeek ¬∑ xAI ¬∑ Ollama Community ¬∑ MCP Contributors

---

Fragen? Issue oder Discussions √∂ffnen.
    providers:
      # OpenAI
      - id: openai
        kind: openai-compat
        baseUrl: https://api.openai.com/v1
        apiKeyRef: OPENAI_API_KEY
        models:
          - name: gpt-4o-mini
            context: 128000
            caps: ["cheap","tools","json"]
            price:
              inputPerMTok: 0.15
              outputPerMTok: 0.60
      
      # Lokale Modelle via Ollama
      - id: ollama
        kind: ollama
        baseUrl: http://127.0.0.1:11434
        models:
          - name: llama3.3:70b-instruct
            context: 32768
            caps: ["local","long","tools"]
    
    routing:
      rules:
        # Tests ‚Üí g√ºnstige Modelle
        - id: cheap-tests
          if:
            anyKeyword: ["test", "unit test", "boilerplate"]
            fileLangIn: ["ts","js","py"]
          then:
            prefer: ["openai:gpt-4o-mini"]
            target: chat
        
        # Privacy ‚Üí lokal erzwingen
        - id: privacy
          if:
            privacyStrict: true
          then:
            prefer: ["ollama:llama3.3:70b-instruct"]
            target: chat
      
      default:
        prefer: ["openai:gpt-4o-mini", "ollama:llama3.3:70b-instruct"]
        target: chat
```

### VSCode-Einstellungen

```json
{
  "modelRouter.configPath": "${workspaceFolder}/router.config.yaml",

### Testing

  "modelRouter.enablePromptClassifier": false
}
```

### Neue Provider hinzuf√ºgen

## üîë API-Keys einrichten

### Methode 1: Command Palette

1. `Ctrl+Shift+P` ‚Üí "Model Router: Set API Key"
2. Provider-ID eingeben (z.B. `openai`)
3. API-Key eingeben

### Methode 2: Umgebungsvariablen

```bash
# .env oder System-Umgebung
export OPENAI_API_KEY="sk-..."
export DEEPSEEK_API_KEY="sk-..."
export GROK_API_KEY="..."
```

Dann: `Ctrl+Shift+P` ‚Üí "Model Router: Import API Keys"

### Unterst√ºtzte Provider

| Provider | API-Key Format | Basis-URL |
|----------|----------------|-----------|
| OpenAI | `sk-...` | `https://api.openai.com/v1` |
| DeepSeek | `sk-...` | `https://api.deepseek.com/v1` |
| Grok (xAI) | varies | `https://api.x.ai/v1` |
| Phi | varies | provider-specific |
| Ollama | none | `http://127.0.0.1:11434` |

## üéÆ Nutzung

### Chat-Interface Varianten

1. Panel (floating):

```text
Ctrl+Shift+P ‚Üí "Model Router: Open Chat UI"
```

1. Docked View (Explorer): automatisch sichtbar falls Einstellung aktiv (`modelRouter.chat.showDockView`).

Funktionen im Chat:

- Eingabefeld mit Shift+Enter = Zeilenumbruch, Enter = Senden
- Toolbar Buttons: Tools, Mikrofon (Voice starten), Speaker (Placeholder), Attach (Dateien ausw√§hlen), Plan, Settings
- Modell-Auswahl (Override) oben links (`auto` = Router entscheidet)
- Anh√§nge werden vor Versand auf max. Anzahl/Gr√∂√üe gek√ºrzt und Geheimnisse (Regex) geschw√§rzt
- Streaming der Antwort in Nachricht, Abschluss zeigt Token & Kosten
- Info-Messages (Simulation, Plan, Budget) erscheinen kursiv

QuickPrompt (Kompaktmodus):

```text
Einstellung: "modelRouter.chat.compactMode": true
Command: "Model Router: Quick Prompt (Kompaktmodus)"
```
Sendet Prompt ohne zuerst Panel zu √∂ffnen. Falls Chat offen ist, wird dort gestreamt, sonst Output-Channel.
### Docked Chat View

Die andockbare Ansicht (`üí¨ Model Router Chat (Dock)`) zeigt denselben Verlauf wie das Panel. Beide Oberfl√§chen sind synchron (Modelle, History, Streaming). Zum Ausblenden: Rechtsklick auf Titel ‚Üí Hide oder Einstellung `modelRouter.chat.showDockView` deaktivieren.

### Tools-Men√º

Command oder Toolbar ‚Üí Optionen:

- Routing-Simulation (zeigt ausgew√§hltes Modell + Alternativen)
- Kosten / Budget √úbersicht (heute / Monat / total)
- Letzte Antwort erneut senden
- Verlauf l√∂schen (auch Persistenz zur√ºckgesetzt)

### Plan / Agent

1. Command: "Plan / Agent aus letztem Prompt" ‚Üí erzeugt nummerierten Plan (max 7 Schritte)
2. Command: "Ausgef√ºhrten Plan starten" ‚Üí f√ºhrt Schritte nacheinander aus

W√§hrend der Ausf√ºhrung:

- Jeder Schritt wird erneut geroutet (modell-spezifisch) und gestreamt
- Kosten/Laufzeit pro Schritt werden erfasst (Budget greift weiterhin)
- Chat-Verlauf erh√§lt k√ºnstliche User-Nachricht `[Plan Schritt X]` + Antwort
- Statusbar zeigt `$(sync~spin) Plan X/N` bis Abschluss oder Abbruch
- Abbruch: Command "Plan-Ausf√ºhrung abbrechen" ‚Üí aktueller Request wird via AbortController beendet

Nach Abschluss: Statusbar entfernt Plan-Indikator; Chat erh√§lt Abschluss-Info.

### Anh√§nge & Redaktion

Konfigurierbar √ºber Einstellungen:

```json
{
  "modelRouter.chat.attachment.maxFiles": 5,

### Logs aktivieren

  "modelRouter.chat.attachment.redactSecrets": true,
  "modelRouter.chat.attachment.additionalRedactPatterns": [
    "(?i)password\\s*[:=]\\s*['\"]?[A-Za-z0-9!@#$%^&*_-]{6,}"
  ]
}

  ### Debug-Mode

Zu gro√üe Dateien (>512KB) werden √ºbersprungen. Nur die ersten N Bytes (Snippet) werden angezeigt. Geheimnisse durch Regex ‚Üí `[REDACTED]`.

### Persistenter Verlauf

`modelRouter.chat.persistHistory`: speichert die letzten 1000 Nachrichten (user/assistant) in globalState. Abschaltbar f√ºr Privacy.

### Voice-State Integration

Wenn Voice aktiviert ist (Konfig), wird der Zustand live im Chat angezeigt (idle/listening/recording/processing). Wechsel per Voice Commands / Toolbar.

### Neue Commands (Zusatz)

| Command | Zweck |
|---------|-------|
| Model Router: Open Chat UI | Panel √∂ffnen |
| Model Router: Quick Prompt (Kompaktmodus) | Schneller Prompt ohne Panel |
| Model Router: Chat Tools | Tools-Men√º |
| Model Router: Plan / Agent aus letztem Prompt | Plan generieren |
| Model Router: Ausgef√ºhrten Plan starten | Plan jetzt sequenziell ausf√ºhren (Streaming + Kosten) |
| Model Router: Plan-Ausf√ºhrung abbrechen | Laufende Plan-Ausf√ºhrung stoppen |

### Relevante Einstellungen (Erweiterung)

| Einstellung | Beschreibung |
|------------|--------------|
| modelRouter.chat.compactMode | QuickPrompt statt Panel-Fluss |
| modelRouter.chat.persistHistory | Verlauf zwischen Sessions speichern |
| modelRouter.chat.showDockView | Docked Chat im Explorer |
| modelRouter.chat.attachment.maxFiles | Max. Anzahl Anh√§nge |
| modelRouter.chat.attachment.maxSnippetBytes | Snippet-Limit pro Datei |
| modelRouter.chat.attachment.redactSecrets | Aktiviert automatische Geheimnis-Redaktion |
| modelRouter.chat.attachment.additionalRedactPatterns | Zus√§tzliche Regexe |

### Einmaliges Routing

```text
Ctrl+Shift+P ‚Üí "Model Router: Route Prompt Once"
```

- Text im Editor ausw√§hlen
- Modellvorschlag ohne Ausf√ºhrung
- Zeigt Score und Begr√ºndung

### Modi wechseln

Klick auf Statusbar oder:

```text
Ctrl+Shift+P ‚Üí "Model Router: Switch Mode"
```

**Verf√ºgbare Modi:**

- `auto` ‚Äì Intelligente Auswahl basierend auf Kontext
- `speed` ‚Äì Schnellste verf√ºgbare Modelle
- `quality` ‚Äì Hochwertigste Modelle (teurer)
- `cheap` ‚Äì G√ºnstigste Modelle
- `local-only` ‚Äì Nur lokale Modelle (Ollama)
- `privacy-strict` ‚Äì Strenger Datenschutz, keine externen APIs

### Weitere Commands

| Command | Beschreibung |
|---------|--------------|
| `Model Router: Open Config` | Konfigurationsdatei √∂ffnen |
| `Model Router: Show Costs` | Ausgaben-√úbersicht |
| `Model Router: Test Connection` | Provider-Verbindungen testen |
| `Model Router: Classify Prompt` | Prompt-Klassifikation anzeigen |
| `Model Router: Simulate Routing` | Routing simulieren |

## üìä Routing-Regeln

### Regel-Struktur

```yaml
- id: regel-name
  if:
    anyKeyword: ["test", "debug"]      # Enth√§lt eines dieser W√∂rter
    allKeywords: ["fix", "bug"]        # Enth√§lt alle diese W√∂rter  
    fileLangIn: ["ts", "js", "py"]     # Dateityp
    filePathMatches: ["**/test/**"]    # Pfad-Pattern
    minContextKB: 128                  # Mindest-Dateigr√∂√üe
    maxContextKB: 512                  # Maximal-Dateigr√∂√üe
    privacyStrict: true                # Privacy-Modus
    mode: ["quality", "speed"]         # Aktiver Modus
  then:
    prefer: ["provider:model", "..."]  # Bevorzugte Modelle
    target: chat                       # Ziel-Art
    priority: 10                       # Zus√§tzliche Priorit√§t
```

### Beispiel-Regeln

```yaml
# Unit Tests ‚Üí g√ºnstige Modelle
- id: unit-tests
  if:
    anyKeyword: ["test", "spec", "jest", "pytest"]
    fileLangIn: ["ts", "js", "py"]
  then:
    prefer: ["openai:gpt-4o-mini", "phi:phi-4-mini"]
    target: chat

# Komplexe Algorithmen ‚Üí Reasoning-Modelle  
- id: complex-algorithms
  if:
    anyKeyword: ["algorithm", "complexity", "optimize", "prove"]
  then:
    prefer: ["deepseek:deepseek-r1", "openai:gpt-4.1"]
    target: chat

# Gro√üe Refactorings ‚Üí Long-Context
- id: large-refactor
  if:
    minContextKB: 200
    anyKeyword: ["refactor", "restructure"]
  then:
    prefer: ["openai:gpt-4.1", "phi:phi-4"]
    target: chat

# Privacy-Mode ‚Üí nur lokal
- id: privacy-only
  if:
    privacyStrict: true
  then:
    prefer: ["ollama:llama3.3:70b-instruct"]
    target: chat
```

## üí∞ Budget-Management

### Konfiguration

```yaml
budget:
  dailyUSD: 5.0        # Tagesdeckel
  monthlyUSD: 100.0    # Monatsdeckel  
  hardStop: true       # Bei √úberschreitung stoppen
  warningThreshold: 80 # Warnung bei 80% Verbrauch
```

### Kosten-Tracking

- Automatische Kostenerfassung nach jeder API-Anfrage
- Aufschl√ºsselung nach Provider und Modell
- Export f√ºr externe Analyse
- Budget-Warnungen und Hard-Stops

### Commands

```text
Model Router: Show Costs     # Ausgaben-√úbersicht
```

### Statusbar-Anzeige (Budget)

Die Statusleiste zeigt ‚Äì sofern aktiviert ‚Äì den aktuellen Modus und optional den Budgetverbrauch an.

Bei laufender Plan-Ausf√ºhrung wird zus√§tzlich ein Spinner + Fortschritt angeh√§ngt:

```text
$(rocket) Router: auto (2) | $0.12/2.50 | $(sync~spin) Plan 2/5
```

Abbruch zeigt kurz `Plan Abbruch‚Ä¶`, danach verschwindet der Indikator.

Einstellungen (`settings.json`):
```json
{
  "modelRouter.showBudgetInStatusBar": true,

### v0.2.0

}
```

### v0.3.0

Modi:
- `compact`: `Router: auto (2) | $0.12/2.50`
- `detailed`: `Router: auto (2) | d:0.12/2.50 (5%) m:2.30/100 (2%)`

Legende:
- `d:` Tagesverbrauch / Tageslimit (+ Prozent)
- `m:` Monatsverbrauch / Monatslimit (+ Prozent)
- Fehlt ein Monatsbudget, wird nur der Tageswert angezeigt.

Farbanpassung erfolgt aktuell nicht dynamisch; Warnungen (z.B. 80% erreicht) erscheinen als VSCode-Notification und im Output-Channel. Hard-Stops verhindern weitere Aufrufe √ºber dem Limit, sofern `hardStop: true` gesetzt ist.

Zeigt:
- Tagesausgaben vs. Budget
- Monatsausgaben vs. Budget  
- Transaktionsanzahl
- Top-Provider und -Modelle
- Ausgaben-Trend

## üîí Datenschutz & Sicherheit

### API-Key-Sicherheit
- **VSCode SecretStorage**: Nutzt System-Keychain (Windows Credential Manager, macOS Keychain, Linux Secret Service)
- **Keine Klartext-Speicherung**: Keys werden nie in Konfigurationsdateien gespeichert
- **Umgebungsvariablen-Fallback**: Sichere Alternative f√ºr Team-Setups

### Privacy-Modi

**`privacy-strict` Modus:**
- Erzwingt lokale Modelle (Ollama)
- Blockiert alle externen API-Calls
- Redaktiert sensible Dateipfade
- Strippt gro√üe Dateien automatisch

**Datenschutz-Filter:**
```yaml
privacy:
  redactPaths: 
    - "**/secrets/**"
    - "**/.env*" 
    - "**/credentials/**"
  stripFileContentOverKB: 256
  allowExternal: false  # Bei privacy-strict
```

### Offline-Betrieb
```yaml
mode: offline  # oder local-only
```
- Nur Ollama-Provider aktiv
- Keine Internetverbindung erforderlich
- Vollst√§ndig lokale Verarbeitung

## üõ†Ô∏è Entwicklung

### Testing

```bash
npm run watch    # Auto-compile
F5               # Launch Extension Development Host

# Provider-Verbindungen testen
Ctrl+Shift+P ‚Üí "Model Router: Test Connection"

# Routing-Simulation
Ctrl+Shift+P ‚Üí "Model Router: Simulate Routing"
```

### Neue Provider hinzuf√ºgen

1. Provider-Klasse in `src/providers/` erstellen
2. `BaseProvider` erweitern
3. In `extension.ts` registrieren
4. Konfiguration in `router.config.yaml` erg√§nzen
‚îú‚îÄ‚îÄ promptClassifier.ts    # KI-Klassifikation
‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îú‚îÄ‚îÄ base.ts          # Provider-Interface
‚îÇ   ‚îú‚îÄ‚îÄ openaiCompat.ts  # OpenAI-kompatibel
‚îÇ   ‚îî‚îÄ‚îÄ ollama.ts        # Lokale Modelle
‚îî‚îÄ‚îÄ mcp/
    ‚îî‚îÄ‚îÄ server.ts        # MCP-Integration
```

### Testing
```bash
# Extension in Development Host starten
npm run watch    # Auto-compile
F5              # Launch Extension Development Host

# Provider-Verbindungen testen
Ctrl+Shift+P ‚Üí "Model Router: Test Connection"

# Routing-Simulation
Ctrl+Shift+P ‚Üí "Model Router: Simulate Routing"
```

### Neue Provider hinzuf√ºgen
1. Provider-Klasse in `src/providers/` erstellen
2. `BaseProvider` erweitern
3. In `extension.ts` registrieren
4. Konfiguration in `router.config.yaml` erg√§nzen

## üîß Problembehandlung

### H√§ufige Probleme

#### "Router nicht initialisiert"

- Konfigurationsdatei pr√ºfen: `Model Router: Open Config`
- API-Keys setzen: `Model Router: Set API Key`
- Extension neu laden: `Developer: Reload Window`

#### "Provider nicht verf√ºgbar"

- Verbindung testen: `Model Router: Test Connection`
- API-Key pr√ºfen
- Firewall/Proxy-Einstellungen √ºberpr√ºfen

#### "Kein passendes Modell gefunden"

- Routing-Regeln in Konfiguration pr√ºfen
- Fallback-Modelle definieren
- Provider-Verf√ºgbarkeit testen

#### Ollama-Probleme

```bash
# Ollama installieren
curl -fsSL https://ollama.ai/install.sh | sh

# Modell laden
ollama pull llama3.3:70b-instruct
ollama pull qwen2.5-coder:32b-instruct

# Server starten
ollama serve
```

### Logs aktivieren
Output-Channel √∂ffnen: "View" ‚Üí "Output" ‚Üí "Model Router"

### Debug-Mode
```json
{
  "modelRouter.debug": true

### v0.4.0

```

```text
src/
‚îú‚îÄ‚îÄ extension.ts           # VSCode Extension Entry Point
‚îú‚îÄ‚îÄ config.ts              # YAML-Konfiguration  
‚îú‚îÄ‚îÄ router.ts              # Routing-Engine
‚îú‚îÄ‚îÄ secret.ts              # API-Key-Management
‚îú‚îÄ‚îÄ price.ts               # Kostenberechnung
‚îú‚îÄ‚îÄ promptClassifier.ts    # KI-Klassifikation
‚îú‚îÄ‚îÄ providers/
‚îî‚îÄ‚îÄ server.ts              # MCP-Integration
### Pull Requests

1. Fork erstellen
2. Feature-Branch: `git checkout -b feature/neue-funktion`
3. Tests hinzuf√ºgen
4. PR erstellen mit Beschreibung

### Provider-Requests

Neue Provider k√∂nnen angefragt werden. Ben√∂tigt:

- API-Dokumentation
- Preismodell
- Beispiel-API-Keys (f√ºr Tests)

## üìã Roadmap

### v0.2.0
- [ ] Webview-Chat-Interface
- [ ] Tool-Calling-Unterst√ºtzung
- [ ] Vollst√§ndige MCP-Integration
- [ ] Team-Konfigurationen

### v0.3.0
- [ ] Anthropic Claude Support
- [ ] Azure OpenAI Integration
- [ ] Performance-Benchmarking
- [ ] A/B-Testing f√ºr Modelle

### v0.4.0
- [ ] Workflow-Automatisierung
- [ ] GitHub Copilot Integration
- [ ] Enterprise-Features
- [ ] Telemetrie-Dashboard

## üìÑ Lizenz

MIT License - siehe [LICENSE](LICENSE) f√ºr Details.

## üôè Danksagungen

- VSCode Team f√ºr die Extension API
- OpenAI, DeepSeek, xAI f√ºr die APIs
- Ollama Community f√ºr lokale Modelle
- MCP-Protokoll Contributors

---

**Weitere Fragen?** √ñffne ein [Issue](../../issues) oder schaue in die [Diskussionen](../../discussions).
