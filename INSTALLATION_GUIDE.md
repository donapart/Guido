# Guido Model Router Extension v0.2.0 - Installation Guide

## ðŸš€ Schnelle Installation

### Manuelle Installation der neuen Provider

Da die VSCE-Paketerstellung derzeit Probleme hat, kÃ¶nnen Sie die neuen OpenRouter und Hugging Face Provider manuell zur bestehenden Extension hinzufÃ¼gen:

### Schritt 1: Extension v0.1.9 installieren
```bash
code --install-extension model-router-0.1.9.vsix
```

### Schritt 2: Neue Provider-Dateien kopieren
Die kompilierten Provider befinden sich in:
- `out/providers/openrouter.js` 
- `out/providers/huggingface.js`

Kopieren Sie diese Dateien in das Extension-Verzeichnis:
```
%USERPROFILE%\.vscode\extensions\model-router.model-router-0.1.9\out\providers\
```

### Schritt 3: VS Code neu starten
Starten Sie VS Code neu, damit die neuen Provider geladen werden.

## ðŸ”§ Konfiguration

### API-SchlÃ¼ssel einrichten
Ã–ffnen Sie VS Code Settings (`Ctrl+,`) und fÃ¼gen Sie hinzu:

```json
{
  "modelRouter.openrouterApiKey": "YOUR_OPENROUTER_API_KEY",
  "modelRouter.huggingfaceApiKey": "YOUR_HUGGINGFACE_API_KEY",
  "modelRouter.anthropicApiKey": "YOUR_ANTHROPIC_API_KEY",
  "modelRouter.cohereApiKey": "YOUR_COHERE_API_KEY"
}
```

### API-SchlÃ¼ssel erhalten

#### OpenRouter API Key
1. Besuchen Sie: https://openrouter.ai/
2. Registrieren Sie sich fÃ¼r ein kostenloses Konto
3. Gehen Sie zu "API Keys" und erstellen Sie einen neuen SchlÃ¼ssel
4. Kopieren Sie den SchlÃ¼ssel in die VS Code Settings

#### Hugging Face API Key
1. Besuchen Sie: https://huggingface.co/
2. Registrieren Sie sich fÃ¼r ein kostenloses Konto
3. Gehen Sie zu Settings â†’ Access Tokens
4. Erstellen Sie einen neuen Token mit "Read" Berechtigung
5. Kopieren Sie den Token in die VS Code Settings

## ðŸŽ¯ Verwendung

### OpenRouter Provider
- Zugriff auf 100+ Modelle von verschiedenen Anbietern
- Modellformat: `provider/model` (z.B. `openai/gpt-4o`, `anthropic/claude-3-5-sonnet`)
- Automatische KostenschÃ¤tzung
- Streaming-Chat UnterstÃ¼tzung

### Hugging Face Provider
- Zugriff auf Open Source Modelle
- UnterstÃ¼tzt Chat-, Code- und Text-Generation-Modelle
- Kostenlose API mit Rate Limits
- Automatische Modell-Erkennung

### Commands
- `Ctrl+Shift+P` â†’ "Model Router: Chat"
- WÃ¤hlen Sie einen Provider (openrouter, huggingface, anthropic, cohere)
- WÃ¤hlen Sie ein Modell
- Starten Sie den Chat!

## ðŸ“‹ VerfÃ¼gbare Modelle

### OpenRouter
- **OpenAI**: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
- **Anthropic**: claude-3-5-sonnet, claude-3-opus, claude-3-haiku
- **Meta**: llama-3.1-70b-instruct, llama-2-chat
- **Google**: gemini-pro, palm-2
- **Mistral**: mistral-7b-instruct, mixtral-8x7b

### Hugging Face
- **Chat**: microsoft/DialoGPT-large
- **Code**: Salesforce/codegen-2B-multi, bigcode/santacoder
- **Text**: gpt2-xl, EleutherAI/gpt-j-6B
- **Instruction**: google/flan-t5-xl
- **Llama**: meta-llama/Llama-2-7b-chat-hf

## ðŸ”§ Entwickler-Info

### Projektstruktur
```
src/providers/
â”œâ”€â”€ openrouter.ts      # Universal API Gateway
â”œâ”€â”€ huggingface.ts     # HF Inference API
â”œâ”€â”€ anthropic.ts       # Claude Models
â”œâ”€â”€ cohere.ts          # Command Models
â”œâ”€â”€ ollama.ts          # Local Models
â””â”€â”€ base.ts           # Provider Interface
```

### Kompilierung
```bash
npm run compile
```

## ðŸŽ‰ Features

- âœ… Voice Control mit "Guido" Wake Word
- âœ… Advanced Dashboard
- âœ… Multi-Provider Support
- âœ… Context-Aware Commands
- âœ… Experimental Features
- âœ… **NEU**: OpenRouter Universal Gateway
- âœ… **NEU**: Hugging Face Open Source Models

---

**Viel SpaÃŸ mit den neuen AI-Providern!** ðŸš€ðŸ¤–
